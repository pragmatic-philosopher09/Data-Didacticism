{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc6z9bNNYruu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Manual Softmax Computation & Evaluation**"
      ],
      "metadata": {
        "id": "bvdnrGQUKycU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)"
      ],
      "metadata": {
        "id": "iiR1xn0yY5ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([2.2, 4.6, 6.8, 1.23, 1.58])\n",
        "outputs = softmax(x)\n",
        "print('Softmax Matrix In Numpy ==> ',outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3fNaeAzZGVX",
        "outputId": "d8042ca6-af5f-4fb6-e966-afd8b5817815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax Matrix In Numpy ==>  [0.00889486 0.09804958 0.88489874 0.00337189 0.00478494]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Softmax Computation & Evaluation Using Tensor Functions**"
      ],
      "metadata": {
        "id": "WGoAmNUYK3Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.2, 4.6, 6.8, 1.23, 1.58])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "\n",
        "print('Softmax Matrix In Tensor ==> ',outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSOZrgxBZSXe",
        "outputId": "76fc4bf1-b3f3-4593-b0e8-1b1c29d982cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax Matrix In Tensor ==>  tensor([0.0089, 0.0980, 0.8849, 0.0034, 0.0048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Manual Cross-Entropy Loss Computation**"
      ],
      "metadata": {
        "id": "z5vdSyfkLIR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_act, y_pred):\n",
        "  celoss = -np.sum(y_act*np.log(y_pred))\n",
        "  return celoss # This is not normalized cross-entropy loss {for normalizing we divide by sample size ==> y_pred[0].shape}"
      ],
      "metadata": {
        "id": "K7oaWpMxZybK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.array([1,0,0])\n",
        "Y_pred_good = np.array([0.9,0.1,0.2])\n",
        "Y_pred_bad = np.array([0.14,0.7,0.69])\n",
        "\n",
        "ce_good = cross_entropy(Y,Y_pred_good)\n",
        "ce_bad = cross_entropy(Y,Y_pred_bad)\n",
        "\n",
        "print(ce_good)\n",
        "print(ce_bad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0lJe2MnJ__X",
        "outputId": "ef535c42-5897-4f0d-f3e3-01ee0489b2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10536051565782628\n",
            "1.9661128563728327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Cross-Entropy Loss Computation & Evaluation Using Tensor Functions**"
      ],
      "metadata": {
        "id": "PhGvMZnWLQAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Note:**\n",
        "\n",
        "#### nn.CrossEntropyLoss applies:\n",
        "\n",
        "#### --> nn.LogSoftMax + nn.NLLLoss (negative log likelihood loss)\n",
        "\n",
        "#### --> We don't need to apply softmax function in last layer\n",
        "\n",
        "#### --> Y should have only class labels when we provide input to nn.CrossEntropyLoss.\n",
        "\n",
        "#### --> Similarly, Y_pred should have only raw scores(logits) and no softmax!"
      ],
      "metadata": {
        "id": "IYCEYFXOdsjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = torch.tensor([0]) # This means correct class label = '0' {we aren't doing one-hot encoding}\n",
        "\n",
        "# nsamples x nclasses = 1x3\n",
        "\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # Classes are '0', '1', '2' with highest weightage belonging to class '0', which means more accurate prediction, which means lower cross-entropy loss value.\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])  # Same as above, just weightage of class '0' is less as compared to class '1', so prediction is pooer, so more loss-value.\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(\"Better prediction loss ==> \",l1.item())\n",
        "print(\"Worse prediction loss ==> \",l2.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgG-Qlj7KjNR",
        "outputId": "544d6f34-eb0f-43ac-c306-e6f7e5518ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better prediction loss ==>  0.4170299470424652\n",
            "Worse prediction loss ==>  1.840616226196289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, prediction1 = torch.max(Y_pred_good, 1) # '1' denotes first dimension\n",
        "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
        "\n",
        "print(prediction1) # Gives o/p of highest probability class --> '0' in this case\n",
        "print(prediction2) # Same as above --> '1' in this case"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhAIMxlxiO6s",
        "outputId": "972484f4-77a0-4520-dbef-720de3ce0f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0])\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_new = torch.tensor([2,0,1]) # Denoting that classes '2', '0' & '1' are correct classes respectively for the samples\n",
        "\n",
        "# n_samples x n_classes = 3x3\n",
        "                                   # Class '2' highest weightage;  Class '0' highest weightage;      Class '1' highest weightage;\n",
        "                                   #   so pred = class '2'           so pred = class '0'                 so pred = class '1'\n",
        "                                   #   |                                |                                |\n",
        "                                   #   |                                |                                |\n",
        "                                   #   V                                V                                V\n",
        "\n",
        "Y_pred_good_new = torch.tensor([ [0.1, 1.0, 2.1],              [2.0, 1.0, 0.1],                   [0.1, 3.0, 0.1] ])\n",
        "\n",
        "\n",
        "Y_pred_bad_new = torch.tensor([ [2.1, 1.0, 0.1],[2.0, 1.0, 2.1],[0.1, 3.0, 0.1] ])\n",
        "\n",
        "l1_new = loss(Y_pred_good_new, Y_new)\n",
        "l2_new = loss(Y_pred_bad_new, Y_new)\n",
        "\n",
        "print(l1)\n",
        "print(l2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2EPOm-qyBa",
        "outputId": "dd4d0485-4b16-4ee6-ba72-f4611f4687d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4170)\n",
            "tensor(1.8406)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, prediction1_new = torch.max(Y_pred_good_new, 1)\n",
        "_, prediction2_new = torch.max(Y_pred_bad_new, 1)\n",
        "\n",
        "print(prediction1_new)\n",
        "print(prediction2_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtnT257_uwLi",
        "outputId": "4f0428ed-9bbb-46e9-ea8c-a3b2c1bac951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 0, 1])\n",
            "tensor([0, 2, 1])\n"
          ]
        }
      ]
    }
  ]
}