{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Four-pronged step:\n",
        "\n",
        "##### (1) Design model --> input size, output size, forward pass\n",
        "\n",
        "##### (2) Construct loss and optimizer\n",
        "\n",
        "##### (3) Training Loop:\n",
        "#####      - Forward Pass: compute gradients\n",
        "\n",
        "#####     - Backward Pass: compute gradients\n",
        "#####          - Update weights"
      ],
      "metadata": {
        "id": "YCcsrDJgHDm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFwOEvhc4LbG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as neural"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "\n",
        "Y = torch.tensor([[2], [4], [6],[8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([25], dtype = torch.float32) #value to be tested"
      ],
      "metadata": {
        "id": "EGCsgIdR8-Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X.shape"
      ],
      "metadata": {
        "id": "-GPFfjz89YyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = n_features\n",
        "output_size = n_features"
      ],
      "metadata": {
        "id": "9HJecTIm-DjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = neural.Linear(input_size, output_size) # PyTorch Function Initialization for forward pass"
      ],
      "metadata": {
        "id": "5eOsbB6L9dPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Predicted Value Before Training: f(25) = {model(X_test).item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPNzA1vqI-2B",
        "outputId": "b4dfb434-dd4c-4934-81d2-409d84f4a256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value Before Training: f(25) = 3.9163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = neural.MSELoss() #PyTorch Function Initialization for computing MSE"
      ],
      "metadata": {
        "id": "W8cWB3rODnVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 250\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #model.parameters(): returns weights and biases.\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X) # Initiating a forward pass for prediction\n",
        "\n",
        "  loss_val = loss(Y,y_pred) # Computing the loss value\n",
        "\n",
        "  loss_val.backward() # For gradient computation\n",
        "\n",
        "  optimizer.step() # Automatic updating weights computed by SGD\n",
        "\n",
        "  optimizer.zero_grad() # Emptying the gradient\n",
        "\n",
        "  if (epoch%10 == 0):\n",
        "    [w,b] = model.parameters() #unpacking weights and biases --> weights is of 2D nature as per our initialization\n",
        "    print(f'Epoch #{epoch+1}: w = {w[0][0].item():.2f}, loss = {loss_val:.8f}')\n",
        "\n",
        "print(f'Predicted Value After Training: f(25) = {model(X_test).item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0_IGj2yClFc",
        "outputId": "6329a1c6-4264-43e4-fd60-86ee7783ec3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1: w = 2.61, loss = 20.50100136\n",
            "Epoch #11: w = 1.74, loss = 0.12901093\n",
            "Epoch #21: w = 1.79, loss = 0.06657090\n",
            "Epoch #31: w = 1.85, loss = 0.03624517\n",
            "Epoch #41: w = 1.89, loss = 0.01973473\n",
            "Epoch #51: w = 1.92, loss = 0.01074514\n",
            "Epoch #61: w = 1.94, loss = 0.00585049\n",
            "Epoch #71: w = 1.95, loss = 0.00318546\n",
            "Epoch #81: w = 1.97, loss = 0.00173441\n",
            "Epoch #91: w = 1.98, loss = 0.00094435\n",
            "Epoch #101: w = 1.98, loss = 0.00051418\n",
            "Epoch #111: w = 1.99, loss = 0.00027996\n",
            "Epoch #121: w = 1.99, loss = 0.00015243\n",
            "Epoch #131: w = 1.99, loss = 0.00008300\n",
            "Epoch #141: w = 1.99, loss = 0.00004519\n",
            "Epoch #151: w = 2.00, loss = 0.00002460\n",
            "Epoch #161: w = 2.00, loss = 0.00001340\n",
            "Epoch #171: w = 2.00, loss = 0.00000729\n",
            "Epoch #181: w = 2.00, loss = 0.00000397\n",
            "Epoch #191: w = 2.00, loss = 0.00000216\n",
            "Epoch #201: w = 2.00, loss = 0.00000118\n",
            "Epoch #211: w = 2.00, loss = 0.00000064\n",
            "Epoch #221: w = 2.00, loss = 0.00000035\n",
            "Epoch #231: w = 2.00, loss = 0.00000019\n",
            "Epoch #241: w = 2.00, loss = 0.00000010\n",
            "Predicted Value After Training: f(25) = 49.9956\n"
          ]
        }
      ]
    }
  ]
}