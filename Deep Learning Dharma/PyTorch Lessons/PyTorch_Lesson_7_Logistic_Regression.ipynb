{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaH7YPbZUop1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Phase 1: Loading The Dataset for Preparation + Splitting Into Training/Testing Dataset**"
      ],
      "metadata": {
        "id": "Cq4BaGLAPUuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc_data = datasets.load_breast_cancer()\n",
        "X,Y = bc_data.data,bc_data.target"
      ],
      "metadata": {
        "id": "4-agYxoTx21e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples,n_features = X.shape"
      ],
      "metadata": {
        "id": "t6XUWFxHyeD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=213) # Splitting the dataset into training and testing module"
      ],
      "metadata": {
        "id": "_ZXi3qFjymhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Phase 2: Scaling The Features In The Dataset [This Particular Scaling Entailing --> Scaling To Make Zero Mean/Variance]**"
      ],
      "metadata": {
        "id": "7hXYaPvmPRlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "\n",
        "# Feature Scaling ==> variance + mean reduced to zero\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "# Converting from numpy to tensor\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32)) # we need to ensure that tensors are in float32 format\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "\n",
        "Y_train = torch.from_numpy(Y_train.astype(np.float32))\n",
        "Y_test = torch.from_numpy(Y_test.astype(np.float32))\n",
        "\n",
        "# Reshaping\n",
        "\n",
        "Y_train = Y_train.view(Y_train.shape[0],1) # Converting to a column vector\n",
        "Y_test = Y_test.view(Y_test.shape[0],1) # Converting to a column vector --> same dimension as that of input tensor vector"
      ],
      "metadata": {
        "id": "odueMSZu02uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Phase 3: Building Model & Following The Subsequent Regular Steps Of Forward Pass + Loss Computation + Optimizer + Training Loop**"
      ],
      "metadata": {
        "id": "jUN9RwRbQRMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we build the model of Logistic Regression from scratch ==>\n",
        "\n",
        "# Steps:\n",
        "\n",
        "# (1) Model Building + Forward Pass\n",
        "\n",
        "# (2) Loss & Optimizer Formation {Gradient Computation + Weight Updation}\n",
        "\n",
        "# (3) Training loop for the ML/DL part\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, number_of_input_features):\n",
        "    super(LogisticRegression,self).__init__() #constructor calling\n",
        "    self.linear = nn.Linear(number_of_input_features,1) # parameters being passed are input size and output size\n",
        "\n",
        "  def forward(self,x):\n",
        "    Y_pred = torch.sigmoid(self.linear(x))\n",
        "    return Y_pred\n"
      ],
      "metadata": {
        "id": "elZcjHYly0_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(n_features)\n",
        "\n",
        "learning_rate = 10\n",
        "num_epochs = 100000\n",
        "loss_criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "id1Ji3DMfV8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Devising the training loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  y_predicted = model(X_train) # Forward pass for the training dataset\n",
        "\n",
        "  loss = loss_criterion(y_predicted, Y_train) # Computing loss for the training dataset\n",
        "\n",
        "  loss.backward() # Backward pass for computing the gradients\n",
        "\n",
        "  optimizer.step() # Updating the weights of the optimizer\n",
        "\n",
        "  optimizer.zero_grad() # Emptying the gradients\n",
        "\n",
        "  if (epoch+1)%10000 == 0:\n",
        "    print(f'Epoch #{epoch+1}: Loss Value = {loss.item():.8f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd2wPX3LJFsF",
        "outputId": "cebf8736-4478-446a-b1ec-6f2e9acc048f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #10000: Loss Value = 0.01457438\n",
            "Epoch #20000: Loss Value = 0.01071587\n",
            "Epoch #30000: Loss Value = 0.00852573\n",
            "Epoch #40000: Loss Value = 0.00706589\n",
            "Epoch #50000: Loss Value = 0.00601878\n",
            "Epoch #60000: Loss Value = 0.00523194\n",
            "Epoch #70000: Loss Value = 0.00462030\n",
            "Epoch #80000: Loss Value = 0.00413208\n",
            "Epoch #90000: Loss Value = 0.00373411\n",
            "Epoch #100000: Loss Value = 0.00340383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Phase 4: Evaluating The Performance of Model**"
      ],
      "metadata": {
        "id": "g-iEWo8DQrw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *torch.no_grad is one method for evaluating model. Another popular method is [model.eval()](https://stackoverflow.com/questions/55627780/evaluating-pytorch-models-with-torch-no-grad-vs-model-eval)*"
      ],
      "metadata": {
        "id": "7Jqj0RIwSYas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad(): # No need to keep track of gradients/computational graph, therefore applied here\n",
        "\n",
        "  Y_test_pred = model(X_test) # Obtaining the predicted value for the testing dataset\n",
        "  Y_test_pred_class = Y_test_pred.round() # Typically the value returned is a floating type value betwixt 0 & 1 due sigmoid function --> so rounding them off to a binary class\n",
        "\n",
        "  accuracy = Y_test_pred_class.eq(Y_test).sum()/float(Y_test.shape[0]) # Y_test.shape[0] --> returns the number of samples of Y_test that can be used for accuracy calculation\n",
        "\n",
        "  print(f'Accuracy = {accuracy*100:.8f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDQk8a-kMj8h",
        "outputId": "3369f48e-65f6-447d-f29b-28849340f894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 93.85964966%\n"
          ]
        }
      ]
    }
  ]
}